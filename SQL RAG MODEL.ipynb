{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea14e0b5-48df-491e-8093-339f86ccfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import langchain_core.prompts as prompts\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a19a115-75eb-4172-beba-5995349bbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ MySQL connection details\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "username = \"root\"\n",
    "password = \"root\"\n",
    "database_schema = \"car_prediction\"\n",
    "\n",
    "# ✅ Create the MySQL connection URI\n",
    "mysql_uri = f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database_schema}\"\n",
    "\n",
    "# ✅ Initialize SQLDatabase\n",
    "db = SQLDatabase.from_uri(mysql_uri, sample_rows_in_table_info=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349b0205-2aa6-449f-a66b-05c608e50c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "db = SQLDatabase.from_uri(mysql_uri, sample_rows_in_table_info=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb651035-b024-498e-9fc4-fd6cc86648b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context =db.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98727afe-bb18-4580-ac0c-87c110913bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCREATE TABLE predictions (\\n\\tid INTEGER NOT NULL AUTO_INCREMENT, \\n\\tmake_year INTEGER, \\n\\tmileage_kmpl FLOAT, \\n\\tengine_cc FLOAT, \\n\\tfuel_type VARCHAR(50), \\n\\towner_count INTEGER, \\n\\tbrand VARCHAR(50), \\n\\ttransmission VARCHAR(50), \\n\\tcolor VARCHAR(50), \\n\\tservice_history VARCHAR(50), \\n\\taccidents_reported INTEGER, \\n\\tinsurance_valid INTEGER, \\n\\tpredicted_price_usd FLOAT, \\n\\tPRIMARY KEY (id)\\n)COLLATE utf8mb4_0900_ai_ci ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\\n\\n/*\\n1 rows from predictions table:\\nid\\tmake_year\\tmileage_kmpl\\tengine_cc\\tfuel_type\\towner_count\\tbrand\\ttransmission\\tcolor\\tservice_history\\taccidents_reported\\tinsurance_valid\\tpredicted_price_usd\\n1\\t2015\\t4.3\\t1200.0\\tpetrol\\t2\\tkia\\tmanual\\tblack\\tfull\\t0\\t1\\t319247.0\\n*/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974c9636-1c8a-45b4-af87-98844b0030b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM Prompt Template                  \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "Remember : Only provide me the sql query dont include anything else.\n",
    "           Provide me sql query in a single line dont add line breaks.\n",
    "Table Schema:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19f37329-4463-45e4-8005-b58ed7213470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the schema of the database\n",
    "def get_schema(db):\n",
    "    schema = db.get_table_info()\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c497139f-868e-499c-88dd-e7ac1716867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=\"AIzaSyCUEn3fzATMVyQsVQLDoJCRCW3jBklBcwU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920a010e-a413-4fed-aa53-f158cbaed775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SQL query chain using the LLM and the prompt template\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=lambda _: get_schema(db))\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b268233-5ea2-4cd5-ab4f-c2285fae6f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT sum(predicted_price_usd) FROM predictions\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# test the sql quert chain with a sample question\n",
    "resp = sql_chain.invoke({\"question\":\"Total car sales predicted_price_usd\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23cef462-06ce-4453-8b2b-966f66ca03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "query = re.search(r\"```sql\\s*(.*?)\\s*```\", resp, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "if query:\n",
    "    query=query.group(1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b2d6ad1-9a8b-451d-bd6d-d579dc67232b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT sum(predicted_price_usd) FROM predictions'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccdb6022-d0f9-4440-b3b5-887cabb71830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(939752.375,)]'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f0a8f60-fc75-498f-93e2-1c9d1ea1e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82f6c752-bf63-4a67-8b05-2ef5b34c6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model = \"gemma2-9b-it\",\n",
    "    api_key=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcd7a7ce-6421-4f98-8f96-62ce03e51aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tenserflow project\\tfvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "390e8dbd-0fbf-46c2-a906-a32fb5b19d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvar\\AppData\\Local\\Temp\\ipykernel_15316\\108186089.py:1: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LangchainLLMWrapper(llm)\n",
      "C:\\Users\\yuvar\\AppData\\Local\\Temp\\ipykernel_15316\\108186089.py:2: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  evaluator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20bbb387-c1fe-4a21-990f-c02cb84ef592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import AspectCritic, RubricsScore\n",
    "\n",
    "maliciousness_definition = (\n",
    "    \"Is the response intended to harm, deceive, or exploit users?\"\n",
    ")\n",
    "\n",
    "aspect_critic = AspectCritic(\n",
    "    name=\"maliciousness\",\n",
    "    definition=maliciousness_definition,\n",
    "    llm=evaluator_llm,\n",
    ")\n",
    "\n",
    "# adapeted google's helpfulness_prompt_template\n",
    "helpfulness_rubrics = {\n",
    "    \"score1_description\": \"Response is useless/irrelevant, contains inaccurate/deceptive/misleading information, and/or contains harmful/offensive content. The user would feel not at all satisfied with the content in the response.\",\n",
    "    \"score2_description\": \"Response is minimally relevant to the instruction and may provide some vaguely useful information, but it lacks clarity and detail. It might contain minor inaccuracies. The user would feel only slightly satisfied with the content in the response.\",\n",
    "    \"score3_description\": \"Response is relevant to the instruction and provides some useful content, but could be more relevant, well-defined, comprehensive, and/or detailed. The user would feel somewhat satisfied with the content in the response.\",\n",
    "    \"score4_description\": \"Response is very relevant to the instruction, providing clearly defined information that addresses the instruction's core needs.  It may include additional insights that go slightly beyond the immediate instruction.  The user would feel quite satisfied with the content in the response.\",\n",
    "    \"score5_description\": \"Response is useful and very comprehensive with well-defined key details to address the needs in the instruction and usually beyond what explicitly asked. The user would feel very satisfied with the content in the response.\",\n",
    "}\n",
    "\n",
    "rubrics_score = RubricsScore(name=\"helpfulness\", rubrics=helpfulness_rubrics, llm=evaluator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e12eebb-b01d-4fc1-b8ff-e03efa3f3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import ContextPrecision, Faithfulness\n",
    "\n",
    "context_precision = ContextPrecision(llm=evaluator_llm)\n",
    "faithfulness = Faithfulness(llm=evaluator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b76507d-347c-4c22-8eed-61b01a4d08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_contexts = [context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25e53dc8-c508-4ef9-a9bd-e6e7fd2c705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "user_inputs = [\n",
    "    \"Total car sales predicted_price_usd\",\n",
    "    \"What are the car type of sales\",\n",
    "    \"highest amount car sales  Predicted_price_used\",\n",
    "    \"what car lowest mileage and  highest predicted_price_used\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "for question in user_inputs:\n",
    "    resp = sql_chain.invoke({\"question\": question})\n",
    "    match = re.search(r\"```sql\\s*(.*?)\\s*```\", resp, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        query = match.group(1).strip()\n",
    "        responses.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05a09f74-6bde-46bd-a102-9de4c9c5e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "references=[\"SELECT SUM(predicted_price_usd) AS total_sales FROM car_sales;\",\n",
    "             \"SELECT DISTINCT car_typeFROM car_sales;\",\n",
    "             \"SELECT *FROM car_sales ORDER BY predicted_price_usd DESC LIMIT 1;\",\n",
    "             \"SELECT *FROM car_salesORDER BY mileage ASC, predicted_price_usd DESC LIMIT 1;\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4922f0b-26df-4bfd-957f-6d231ccbba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15d3bafe-9947-46bf-892f-54f7ed5979b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(user_inputs)\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8913768e-7fdc-4c3e-937c-b6d6658e568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=user_inputs[i],\n",
    "        retrieved_contexts=list(retrieved_contexts),\n",
    "        response=responses[i],\n",
    "        reference=references[i],\n",
    "    )\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70c728f0-3cf6-4117-97fa-33904b8e5493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total car sales predicted_price_usd</td>\n",
       "      <td>[\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...</td>\n",
       "      <td>SELECT sum(predicted_price_usd) FROM predictions</td>\n",
       "      <td>SELECT SUM(predicted_price_usd) AS total_sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the car type of sales</td>\n",
       "      <td>[\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...</td>\n",
       "      <td>SELECT DISTINCT brand FROM predictions;</td>\n",
       "      <td>SELECT DISTINCT car_typeFROM car_sales;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>highest amount car sales  Predicted_price_used</td>\n",
       "      <td>[\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...</td>\n",
       "      <td>SELECT predicted_price_usd FROM predictions OR...</td>\n",
       "      <td>SELECT *FROM car_sales ORDER BY predicted_pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what car lowest mileage and  highest predicted...</td>\n",
       "      <td>[\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...</td>\n",
       "      <td>SELECT brand FROM predictions ORDER BY mileage...</td>\n",
       "      <td>SELECT *FROM car_salesORDER BY mileage ASC, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                Total car sales predicted_price_usd   \n",
       "1                     What are the car type of sales   \n",
       "2     highest amount car sales  Predicted_price_used   \n",
       "3  what car lowest mileage and  highest predicted...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...   \n",
       "1  [\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...   \n",
       "2  [\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...   \n",
       "3  [\\nCREATE TABLE predictions (\\n\\tid INTEGER NO...   \n",
       "\n",
       "                                            response  \\\n",
       "0   SELECT sum(predicted_price_usd) FROM predictions   \n",
       "1            SELECT DISTINCT brand FROM predictions;   \n",
       "2  SELECT predicted_price_usd FROM predictions OR...   \n",
       "3  SELECT brand FROM predictions ORDER BY mileage...   \n",
       "\n",
       "                                           reference  \n",
       "0  SELECT SUM(predicted_price_usd) AS total_sales...  \n",
       "1            SELECT DISTINCT car_typeFROM car_sales;  \n",
       "2  SELECT *FROM car_sales ORDER BY predicted_pric...  \n",
       "3  SELECT *FROM car_salesORDER BY mileage ASC, pr...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_eval_dataset = EvaluationDataset(samples=samples)\n",
    "ragas_eval_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6f3bc9a-676d-4d8e-bb60-fc44cfd91b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0966eee2da470cb85c575c1dd49762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[5]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[4]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[0]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[7]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[1]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[2]: BadRequestError(Error code: 400 - {'error': {'message': 'The model `gemma2-9b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}})\n",
      "Exception raised in Job[6]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': nan, 'helpfulness': nan}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "ragas_metrics = [ context_precision, rubrics_score]\n",
    "\n",
    "result = evaluate(\n",
    "    metrics=ragas_metrics,\n",
    "    dataset=ragas_eval_dataset\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
